{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "103040fb",
   "metadata": {},
   "source": [
    "# Pre-Processing & Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dbd4d53",
   "metadata": {},
   "source": [
    "## GPU, Imports & Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fd3a5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "print(\"GPU CHECK\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if not torch.cuda.is_available():\n",
    "    raise RuntimeError(\"CUDA not available!\")\n",
    "\n",
    "device = \"cuda\"\n",
    "gpu_name = torch.cuda.get_device_name(0)\n",
    "gpu_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "\n",
    "print(f\"GPU: {gpu_name}\")\n",
    "print(f\"VRAM: {gpu_memory:.1f} GB\")\n",
    "print(f\"CUDA: {torch.version.cuda}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c91fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from torch.cuda.amp import autocast\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import gc\n",
    "from datetime import datetime\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c75b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLOADING DATA\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "TRAIN_CSV = \"squad2_train.csv\"\n",
    "DEV_CSV = \"squad2_dev.csv\"\n",
    "\n",
    "df_train_full = pd.read_csv(TRAIN_CSV)\n",
    "df_dev_full = pd.read_csv(DEV_CSV)\n",
    "\n",
    "print(f\"Train: {len(df_train_full):,} rows\")\n",
    "print(f\"Dev: {len(df_dev_full):,} rows\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9a1322",
   "metadata": {},
   "source": [
    "## 7 Parts with 1st part 10k, and 6-20k parts split into 5 parts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f74eccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSPLITTING TRAIN DATA INTO 7 PARTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "splits = [\n",
    "    ('A', 0, 10000, 10000),\n",
    "    ('B', 10000, 30000, 20000),\n",
    "    ('C', 30000, 50000, 20000),\n",
    "    ('D', 50000, 70000, 20000),\n",
    "    ('E', 70000, 90000, 20000),\n",
    "    ('F', 90000, 110000, 20000),\n",
    "    ('G', 110000, 130319, 20319)\n",
    "]\n",
    "\n",
    "parts = {}\n",
    "for part_name, start, end, size in splits:\n",
    "    parts[part_name] = df_train_full.iloc[start:end].copy()\n",
    "    print(f\"Part {part_name}: Rows {start:,}-{end-1:,} ({size:,} rows)\")\n",
    "\n",
    "print(f\"\\nTotal: {sum([s[3] for s in splits]):,} rows\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9580363",
   "metadata": {},
   "source": [
    "## Configurations, Model and Translation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca18cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "MAX_LENGTH = 384\n",
    "TARGET_LANG = \"tam_Taml\"\n",
    "SOURCE_LANG = \"eng_Latn\"\n",
    "MODEL_NAME = \"facebook/nllb-200-distilled-600M\"\n",
    "\n",
    "print(\"\\nCONFIGURATION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "print(f\"Max Length: {MAX_LENGTH}\")\n",
    "print(f\"Model: {MODEL_NAME}\")\n",
    "print(f\"Target: Tamil\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d3e3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nLOADING MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, src_lang=SOURCE_LANG)\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    MODEL_NAME,\n",
    "    torch_dtype=torch.float16,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6f4ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_batch(texts, batch_size=BATCH_SIZE):\n",
    "    translations = []\n",
    "    \n",
    "    for i in range(0, len(texts), batch_size):\n",
    "        batch = texts[i:i + batch_size]\n",
    "        \n",
    "        inputs = tokenizer(\n",
    "            batch,\n",
    "            return_tensors=\"pt\",\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=MAX_LENGTH\n",
    "        ).to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            with autocast():\n",
    "                outputs = model.generate(\n",
    "                    **inputs,\n",
    "                    forced_bos_token_id=tokenizer.lang_code_to_id[TARGET_LANG],\n",
    "                    max_length=MAX_LENGTH,\n",
    "                    num_beams=1,\n",
    "                    early_stopping=True\n",
    "                )\n",
    "        \n",
    "        batch_translations = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "        translations.extend(batch_translations)\n",
    "        \n",
    "        if i % (batch_size * 10) == 0:\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    return translations\n",
    "\n",
    "print(\"Translation function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92ee7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_dataframe(df, part_name, output_file, batch_size=BATCH_SIZE):\n",
    "    print(f\"\\nTranslating {part_name}: {len(df):,} rows\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    start_time = datetime.now()\n",
    "    df_result = df.copy()\n",
    "    \n",
    "    contexts = df['context'].fillna('').astype(str).tolist()\n",
    "    questions = df['question'].fillna('').astype(str).tolist()\n",
    "    answers = df['answer_text'].fillna('').astype(str).tolist()\n",
    "    \n",
    "    print(\"Translating contexts...\")\n",
    "    contexts_tamil = translate_batch(contexts, batch_size)\n",
    "    \n",
    "    print(\"Translating questions...\")\n",
    "    questions_tamil = translate_batch(questions, batch_size)\n",
    "    \n",
    "    print(\"Translating answers...\")\n",
    "    answers_tamil = translate_batch(answers, batch_size)\n",
    "    \n",
    "    df_result['context_tamil'] = contexts_tamil\n",
    "    df_result['question_tamil'] = questions_tamil\n",
    "    df_result['answer_text_tamil'] = answers_tamil\n",
    "    \n",
    "    df_result.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    elapsed = datetime.now() - start_time\n",
    "    print(f\"\\nCompleted {part_name}\")\n",
    "    print(f\"Time: {elapsed}\")\n",
    "    print(f\"Saved: {output_file}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return df_result\n",
    "\n",
    "print(\"Dataframe translation function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d99c3dcc",
   "metadata": {},
   "source": [
    "## Further Split B-G into 5 Sub-parts Each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3c28d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSPLITTING B-G INTO 5 SUB-PARTS EACH\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "def split_into_5(df, part_name):\n",
    "    size = len(df)\n",
    "    chunk_size = size // 5\n",
    "    \n",
    "    parts = {}\n",
    "    for i in range(1, 6):\n",
    "        start = (i-1) * chunk_size\n",
    "        end = i * chunk_size if i < 5 else size\n",
    "        parts[f\"{part_name}{i}\"] = df.iloc[start:end].copy()\n",
    "        print(f\"  {part_name}{i}: {len(parts[f'{part_name}{i}']):,} rows\")\n",
    "    \n",
    "    return parts\n",
    "\n",
    "parts_B = split_into_5(parts['B'], 'B')\n",
    "parts_C = split_into_5(parts['C'], 'C')\n",
    "parts_D = split_into_5(parts['D'], 'D')\n",
    "parts_E = split_into_5(parts['E'], 'E')\n",
    "parts_F = split_into_5(parts['F'], 'F')\n",
    "parts_G = split_into_5(parts['G'], 'G')\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a31f66",
   "metadata": {},
   "source": [
    "## Split Dev into 3 Sub-parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d9e72c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSPLITTING DEV INTO 3 SUB-PARTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "dev_size = len(df_dev_full)\n",
    "dev_chunk = dev_size // 3\n",
    "\n",
    "parts_Dev = {\n",
    "    'Dev1': df_dev_full.iloc[0:dev_chunk].copy(),\n",
    "    'Dev2': df_dev_full.iloc[dev_chunk:2*dev_chunk].copy(),\n",
    "    'Dev3': df_dev_full.iloc[2*dev_chunk:].copy()\n",
    "}\n",
    "\n",
    "for name, df in parts_Dev.items():\n",
    "    print(f\"{name}: {len(df):,} rows\")\n",
    "\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d12ba4",
   "metadata": {},
   "source": [
    "# Translation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e28a7569",
   "metadata": {},
   "source": [
    "## Part A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ef9e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partA_tamil = translate_dataframe(parts['A'], 'A', 'train_tamil_partA.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f69fb3",
   "metadata": {},
   "source": [
    "## Part B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21fab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partB1_tamil = translate_dataframe(parts_B['B1'], 'B1', 'train_tamil_partB1.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20737ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partB2_tamil = translate_dataframe(parts_B['B2'], 'B2', 'train_tamil_partB2.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab1b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partB3_tamil = translate_dataframe(parts_B['B3'], 'B3', 'train_tamil_partB3.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc26e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partB4_tamil = translate_dataframe(parts_B['B4'], 'B4', 'train_tamil_partB4.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fcc4ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partB5_tamil = translate_dataframe(parts_B['B5'], 'B5', 'train_tamil_partB5.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7e4210",
   "metadata": {},
   "source": [
    "## Part C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65fa8c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partC1_tamil = translate_dataframe(parts_C['C1'], 'C1', 'train_tamil_partC1.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0b4d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partC2_tamil = translate_dataframe(parts_C['C2'], 'C2', 'train_tamil_partC2.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e25224",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partC3_tamil = translate_dataframe(parts_C['C3'], 'C3', 'train_tamil_partC3.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a30d15e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partC4_tamil = translate_dataframe(parts_C['C4'], 'C4', 'train_tamil_partC4.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b80f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partC5_tamil = translate_dataframe(parts_C['C5'], 'C5', 'train_tamil_partC5.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4b4d8cd",
   "metadata": {},
   "source": [
    "## Part D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b24d2ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partD1_tamil = translate_dataframe(parts_D['D1'], 'D1', 'train_tamil_partD1.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d81477",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partD2_tamil = translate_dataframe(parts_D['D2'], 'D2', 'train_tamil_partD2.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10c732a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partD3_tamil = translate_dataframe(parts_D['D3'], 'D3', 'train_tamil_partD3.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b5f3f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partD4_tamil = translate_dataframe(parts_D['D4'], 'D4', 'train_tamil_partD4.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c67da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partD5_tamil = translate_dataframe(parts_D['D5'], 'D5', 'train_tamil_partD5.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32bb2d6",
   "metadata": {},
   "source": [
    "## Part E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86eef5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partE1_tamil = translate_dataframe(parts_E['E1'], 'E1', 'train_tamil_partE1.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee1fd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partE2_tamil = translate_dataframe(parts_E['E2'], 'E2', 'train_tamil_partE2.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partE3_tamil = translate_dataframe(parts_E['E3'], 'E3', 'train_tamil_partE3.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc8af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partE4_tamil = translate_dataframe(parts_E['E4'], 'E4', 'train_tamil_partE4.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28e0c833",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partE5_tamil = translate_dataframe(parts_E['E5'], 'E5', 'train_tamil_partE5.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd98de04",
   "metadata": {},
   "source": [
    "## Part F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c59ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partF1_tamil = translate_dataframe(parts_F['F1'], 'F1', 'train_tamil_partF1.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba7de34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partF2_tamil = translate_dataframe(parts_F['F2'], 'F2', 'train_tamil_partF2.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7c1e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partF3_tamil = translate_dataframe(parts_F['F3'], 'F3', 'train_tamil_partF3.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eee6ea14",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partF4_tamil = translate_dataframe(parts_F['F4'], 'F4', 'train_tamil_partF4.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a7e844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partF5_tamil = translate_dataframe(parts_F['F5'], 'F5', 'train_tamil_partF5.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5db15f36",
   "metadata": {},
   "source": [
    "## Part G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9e23d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partG1_tamil = translate_dataframe(parts_G['G1'], 'G1', 'train_tamil_partG1.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partG2_tamil = translate_dataframe(parts_G['G2'], 'G2', 'train_tamil_partG2.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcbbae07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partG3_tamil = translate_dataframe(parts_G['G3'], 'G3', 'train_tamil_partG3.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0c9d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partG4_tamil = translate_dataframe(parts_G['G4'], 'G4', 'train_tamil_partG4.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098e3770",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_partG5_tamil = translate_dataframe(parts_G['G5'], 'G5', 'train_tamil_partG5.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c16e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ALL TRAIN PARTS COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d42bff0",
   "metadata": {},
   "source": [
    "## Dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d78f432",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTRANSLATING DEV SPLIT - Part 1\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_partDev1_tamil = translate_dataframe(parts_Dev['Dev1'], 'Dev1', 'dev_tamil_partDev1.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nDev complete: {len(df_partDev1_tamil):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0294ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTRANSLATING DEV SPLIT - Part 2\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_partDev2_tamil = translate_dataframe(parts_Dev['Dev2'], 'Dev2', 'dev_tamil_partDev2.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nDev complete: {len(df_partDev2_tamil):,} rows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c5948f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTRANSLATING DEV SPLIT - Part 3\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_partDev3_tamil = translate_dataframe(parts_Dev['Dev3'], 'Dev3', 'dev_tamil_partDev3.csv', BATCH_SIZE)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "\n",
    "print(f\"\\nDev complete: {len(df_partDev3_tamil):,} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00fcda1",
   "metadata": {},
   "source": [
    "# Post-Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2afac5c6",
   "metadata": {},
   "source": [
    "## Concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fe23738",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nCONCATENATING ALL PARTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_train_tamil_complete = pd.concat([\n",
    "    df_partA_tamil,\n",
    "    df_partB1_tamil, df_partB2_tamil, df_partB3_tamil, df_partB4_tamil, df_partB5_tamil,\n",
    "    df_partC1_tamil, df_partC2_tamil, df_partC3_tamil, df_partC4_tamil, df_partC5_tamil,\n",
    "    df_partD1_tamil, df_partD2_tamil, df_partD3_tamil, df_partD4_tamil, df_partD5_tamil,\n",
    "    df_partE1_tamil, df_partE2_tamil, df_partE3_tamil, df_partE4_tamil, df_partE5_tamil,\n",
    "    df_partF1_tamil, df_partF2_tamil, df_partF3_tamil, df_partF4_tamil, df_partF5_tamil,\n",
    "    df_partG1_tamil, df_partG2_tamil, df_partG3_tamil, df_partG4_tamil, df_partG5_tamil\n",
    "], ignore_index=True)\n",
    "\n",
    "df_dev_tamil_complete = pd.concat([\n",
    "    df_partDev1_tamil,\n",
    "    df_partDev2_tamil,\n",
    "    df_partDev3_tamil\n",
    "], ignore_index=True)\n",
    "\n",
    "df_train_tamil_complete.to_csv('squad2_train_tamil_complete.csv', index=False, encoding='utf-8-sig')\n",
    "df_dev_tamil_complete.to_csv('squad2_dev_tamil_complete.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"Train: {len(df_train_tamil_complete):,} rows\")\n",
    "print(f\"Dev: {len(df_dev_tamil_complete):,} rows\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d7c19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nFINAL STATISTICS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nCOMPLETED TRANSLATION:\")\n",
    "print(f\"  Train: {len(df_train_tamil_complete):,} rows\")\n",
    "print(f\"  Dev: {len(df_dev_tamil):,} rows\")\n",
    "print(f\"  Total: {len(df_train_tamil_complete) + len(df_dev_tamil):,} rows\")\n",
    "\n",
    "df_train_tamil_complete['context_ratio'] = (\n",
    "    df_train_tamil_complete['context_tamil'].str.len() / \n",
    "    df_train_tamil_complete['context'].str.len()\n",
    ")\n",
    "df_train_tamil_complete['question_ratio'] = (\n",
    "    df_train_tamil_complete['question_tamil'].str.len() / \n",
    "    df_train_tamil_complete['question'].str.len()\n",
    ")\n",
    "\n",
    "print(f\"\\nLENGTH RATIOS (Tamil/English):\")\n",
    "print(f\"  Context median: {df_train_tamil_complete['context_ratio'].median():.2f}x\")\n",
    "print(f\"  Question median: {df_train_tamil_complete['question_ratio'].median():.2f}x\")\n",
    "\n",
    "print(f\"\\nOUTPUT FILES:\")\n",
    "print(f\"  squad2_train_tamil_complete.csv ({len(df_train_tamil_complete):,} rows)\")\n",
    "print(f\"  squad2_dev_tamil_complete.csv ({len(df_dev_tamil):,} rows)\")\n",
    "print(f\"  train_tamil_partA.csv through partG.csv (backups)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TRANSLATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cff152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nSAMPLE TRANSLATIONS FROM COMPLETE DATASET\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "sample_indices = [0, 15000, 40000, 60000, 80000, 100000, 125000]\n",
    "\n",
    "for idx in sample_indices:\n",
    "    row = df_train_tamil_complete.iloc[idx]\n",
    "    print(f\"\\nSample {idx+1} (Row {idx}):\")\n",
    "    print(f\"  Article: {row['article_title']}\")\n",
    "    print(f\"  \\n  English Q: {row['question']}\")\n",
    "    print(f\"  Tamil Q:   {row['question_tamil']}\")\n",
    "    print(f\"  \\n  English A: {row['answer_text'] if pd.notna(row['answer_text']) else 'N/A'}\")\n",
    "    print(f\"  Tamil A:   {row['answer_text_tamil']}\")\n",
    "    print(\"-\"*80)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"READY FOR BENCHMARKING\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
