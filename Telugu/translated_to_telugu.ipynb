{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/utils/generic.py:441: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/transformers/utils/generic.py:309: FutureWarning: `torch.utils._pytree._register_pytree_node` is deprecated. Please use `torch.utils._pytree.register_pytree_node` instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/opt/anaconda3/envs/nlp/lib/python3.10/site-packages/huggingface_hub/file_download.py:945: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████| 3/3 [01:50<00:00, 36.92s/it]\n"
     ]
    }
   ],
   "source": [
    "# Use a pipeline as a high-level helper\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"translation\", model=\"facebook/nllb-200-3.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model directly\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/nllb-200-distilled-600M\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"facebook/nllb-200-distilled-600M\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_lang = \"eng_Latn\"\n",
    "tgt_lang = \"tel_Telu\"   # Telugu\n",
    "\n",
    "INPUT_CSV  = \"train_dataset.csv\"          \n",
    "OUTPUT_CSV = \"dataset_telugu.csv\"   \n",
    "QUESTION_COL = \"qa_question\"              \n",
    "NEW_COL = \"question_in_telugu\"            \n",
    "MAX_LEN = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train_dataset.csv')\n",
    "\n",
    "if QUESTION_COL not in df.columns:\n",
    "    raise ValueError(f\"Column '{QUESTION_COL}' not found in {INPUT_CSV}\")\n",
    "assert df[QUESTION_COL].isna().sum() == 0, \"Found missing values in questions.\"\n",
    "\n",
    "texts = df[QUESTION_COL].astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.src_lang = src_lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M2M100ForConditionalGeneration(\n",
       "  (model): M2M100Model(\n",
       "    (shared): Embedding(256206, 1024, padding_idx=1)\n",
       "    (encoder): M2M100Encoder(\n",
       "      (embed_tokens): Embedding(256206, 1024, padding_idx=1)\n",
       "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x M2M100EncoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): M2M100Decoder(\n",
       "      (embed_tokens): Embedding(256206, 1024, padding_idx=1)\n",
       "      (embed_positions): M2M100SinusoidalPositionalEmbedding()\n",
       "      (layers): ModuleList(\n",
       "        (0-11): 12 x M2M100DecoderLayer(\n",
       "          (self_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): M2M100Attention(\n",
       "            (k_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (v_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (q_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "            (out_proj): Linear(in_features=1024, out_features=1024, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=1024, out_features=4096, bias=True)\n",
       "          (fc2): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "          (final_layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (lm_head): Linear(in_features=1024, out_features=256206, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_forced_bos_id(tok, lang_code: str):\n",
    "    # 1) Preferred (newer transformers)\n",
    "    if hasattr(tok, \"lang_code_to_id\") and isinstance(getattr(tok, \"lang_code_to_id\"), dict):\n",
    "        if lang_code in tok.lang_code_to_id:\n",
    "            return tok.lang_code_to_id[lang_code]\n",
    "    # 2) Convert token -> id (works in many versions)\n",
    "    try:\n",
    "        tid = tok.convert_tokens_to_ids(lang_code)\n",
    "        if isinstance(tid, int) and tid != tok.unk_token_id:\n",
    "            return tid\n",
    "    except Exception:\n",
    "        pass\n",
    "    # 3) Look up in vocab directly\n",
    "    vocab = tok.get_vocab() if hasattr(tok, \"get_vocab\") else {}\n",
    "    if lang_code in vocab:\n",
    "        return vocab[lang_code]\n",
    "    # 4) As a last resort, raise a clear error\n",
    "    raise RuntimeError(\n",
    "        f\"Could not resolve BOS id for language '{lang_code}'. \"\n",
    "        \"Try updating transformers: pip install -U transformers\"\n",
    "    )\n",
    "\n",
    "FORCED_BOS_ID = get_forced_bos_id(tokenizer, tgt_lang)\n",
    "\n",
    "device = torch.device(\"mps\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_batch(batch_texts):\n",
    "    enc = tokenizer(\n",
    "        batch_texts,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=MAX_LEN,\n",
    "    ).to(device)\n",
    "    \n",
    "    # FIX: Use tokenizer.convert_tokens_to_ids() instead\n",
    "    # Set the target language properly\n",
    "    tokenizer.src_lang = \"eng_Latn\"  # Source language (English)\n",
    "    forced_bos_token_id = tokenizer.convert_tokens_to_ids(tgt_lang)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        gen = model.generate(\n",
    "            **enc,\n",
    "            forced_bos_token_id=forced_bos_token_id,\n",
    "            max_length=MAX_LEN,\n",
    "        )\n",
    "    \n",
    "    return [tokenizer.decode(g, skip_special_tokens=True) for g in gen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Translating to Telugu: 100%|██████████| 4073/4073 [6:10:24<00:00,  5.46s/it]   \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "\n",
    "translated = []\n",
    "for i in tqdm(range(0, len(texts), 32), desc=\"Translating to Telugu\"):\n",
    "    batch = texts[i:i+32]\n",
    "    translated.extend(translate_batch(batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130319"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(translated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[NEW_COL] = translated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>answer_answer_start</th>\n",
       "      <th>answer_text</th>\n",
       "      <th>context</th>\n",
       "      <th>paragraph_index</th>\n",
       "      <th>plausible_answer_answer_start</th>\n",
       "      <th>plausible_answer_text</th>\n",
       "      <th>qa_id</th>\n",
       "      <th>qa_is_impossible</th>\n",
       "      <th>qa_question</th>\n",
       "      <th>qas_index</th>\n",
       "      <th>title</th>\n",
       "      <th>version</th>\n",
       "      <th>question_in_telugu</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>269.0</td>\n",
       "      <td>in the late 1990s</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56be85543aeaaa14008c9063</td>\n",
       "      <td>False</td>\n",
       "      <td>When did Beyonce start becoming popular?</td>\n",
       "      <td>0</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>v2.0</td>\n",
       "      <td>బీయన్స్ ఎప్పుడు ప్రజాదరణ పొందడం ప్రారంభించింది?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>207.0</td>\n",
       "      <td>singing and dancing</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56be85543aeaaa14008c9065</td>\n",
       "      <td>False</td>\n",
       "      <td>What areas did Beyonce compete in when she was...</td>\n",
       "      <td>1</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>v2.0</td>\n",
       "      <td>బీయన్స్ ఏ రంగాల్లో పోటీ పడ్డాడు?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>526.0</td>\n",
       "      <td>2003</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56be85543aeaaa14008c9066</td>\n",
       "      <td>False</td>\n",
       "      <td>When did Beyonce leave Destiny's Child and bec...</td>\n",
       "      <td>2</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>v2.0</td>\n",
       "      <td>బీయన్స్ ఎప్పుడు డెస్టినీ చైల్డ్ను విడిచిపెట్టి...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>166.0</td>\n",
       "      <td>Houston, Texas</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9601</td>\n",
       "      <td>False</td>\n",
       "      <td>In what city and state did Beyonce  grow up?</td>\n",
       "      <td>3</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>v2.0</td>\n",
       "      <td>బీయన్స్ ఏ నగరంలో, ఏ రాష్ట్రంలో పెరిగాడు?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>276.0</td>\n",
       "      <td>late 1990s</td>\n",
       "      <td>Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>56bf6b0f3aeaaa14008c9602</td>\n",
       "      <td>False</td>\n",
       "      <td>In which decade did Beyonce become famous?</td>\n",
       "      <td>4</td>\n",
       "      <td>Beyoncé</td>\n",
       "      <td>v2.0</td>\n",
       "      <td>ఏ దశాబ్దంలో బీయన్స్ ప్రసిద్ధి చెందింది?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   answer_answer_start          answer_text  \\\n",
       "0                269.0    in the late 1990s   \n",
       "1                207.0  singing and dancing   \n",
       "2                526.0                 2003   \n",
       "3                166.0       Houston, Texas   \n",
       "4                276.0           late 1990s   \n",
       "\n",
       "                                             context  paragraph_index  \\\n",
       "0  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                0   \n",
       "1  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                0   \n",
       "2  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                0   \n",
       "3  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                0   \n",
       "4  Beyoncé Giselle Knowles-Carter (/biːˈjɒnseɪ/ b...                0   \n",
       "\n",
       "   plausible_answer_answer_start plausible_answer_text  \\\n",
       "0                            NaN                   NaN   \n",
       "1                            NaN                   NaN   \n",
       "2                            NaN                   NaN   \n",
       "3                            NaN                   NaN   \n",
       "4                            NaN                   NaN   \n",
       "\n",
       "                      qa_id  qa_is_impossible  \\\n",
       "0  56be85543aeaaa14008c9063             False   \n",
       "1  56be85543aeaaa14008c9065             False   \n",
       "2  56be85543aeaaa14008c9066             False   \n",
       "3  56bf6b0f3aeaaa14008c9601             False   \n",
       "4  56bf6b0f3aeaaa14008c9602             False   \n",
       "\n",
       "                                         qa_question  qas_index    title  \\\n",
       "0           When did Beyonce start becoming popular?          0  Beyoncé   \n",
       "1  What areas did Beyonce compete in when she was...          1  Beyoncé   \n",
       "2  When did Beyonce leave Destiny's Child and bec...          2  Beyoncé   \n",
       "3      In what city and state did Beyonce  grow up?           3  Beyoncé   \n",
       "4         In which decade did Beyonce become famous?          4  Beyoncé   \n",
       "\n",
       "  version                                 question_in_telugu  \n",
       "0    v2.0    బీయన్స్ ఎప్పుడు ప్రజాదరణ పొందడం ప్రారంభించింది?  \n",
       "1    v2.0                   బీయన్స్ ఏ రంగాల్లో పోటీ పడ్డాడు?  \n",
       "2    v2.0  బీయన్స్ ఎప్పుడు డెస్టినీ చైల్డ్ను విడిచిపెట్టి...  \n",
       "3    v2.0           బీయన్స్ ఏ నగరంలో, ఏ రాష్ట్రంలో పెరిగాడు?  \n",
       "4    v2.0            ఏ దశాబ్దంలో బీయన్స్ ప్రసిద్ధి చెందింది?  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('translated_to_telugu_train.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
